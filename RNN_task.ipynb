{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rdlulu/Deep-Learning/blob/master/RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9Oki5wn5mpw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07d3c196-2378-466f-dae6-fe9dd396f189"
      },
      "source": [
        "# set tf 1.x for colab\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AalFpl8W6Qp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "de209748-73ae-4246-d6d8-fd3d2fb33392"
      },
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week2_honor()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
            "--2020-07-27 00:20:23--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3636 (3.6K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-07-27 00:20:23 (57.8 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h06Gj8Jx5mp5",
        "colab_type": "text"
      },
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "7_sDAasS5mp6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "74bcadf7-29d7-48e8-dd94-f60d923878a5"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHLqo4Kh5mqA",
        "colab_type": "text"
      },
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "H9A3wRi15mqB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "SC3Ers135mqF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "68f4fc0e-0c01-4af9-fc1f-910e447ba7a6"
      },
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "VV99guz35mqJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 298
        },
        "outputId": "51501b58-f0d3-4db6-f6e8-979dfb2e6437"
      },
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuKb_t295mqL",
        "colab_type": "text"
      },
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "sZwkIWD05mqM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b3406543-16bb-4d7d-bc9e-b40992b1ad09"
      },
      "source": [
        "tokens = set()\n",
        "for name in names:\n",
        "  for ch in name:\n",
        "    tokens.add(ch)\n",
        "  ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "tokens.add(\"#\")\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nyJK3bXxirrx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "964ff948-8ace-4845-a240-e25cdde7a149"
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['V', 'u', ' ', 'b', 'r', '-', 'W', 'q', 'D', 'C', 'h', 'T', 'x', 'F', \"'\", 'g', 'a', 'L', 'E', 'P', 'Q', 'R', 'M', 'K', 'd', 'v', 'f', 'N', 'z', 'I', 'X', 'y', '#', 'Z', 'c', 'm', 'i', 't', 'O', 'p', 'B', 'k', 'l', 's', 'j', 'A', 'J', 'w', 'G', 'n', 'S', 'o', 'U', 'Y', 'H', 'e']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3640rklT5mqS",
        "colab_type": "text"
      },
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "7th89aER5mqT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token_to_id = {key:value for value, key in enumerate(tokens)}\n",
        "\n",
        "### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "jHIBlcFC5mqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "Wjt9wiiI5mqb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "1b573e07-e557-4773-a49b-28bf36338143"
      },
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 2 45  3 16 15 16 55 42 32]\n",
            " [ 2 48 42 51  4 31 32 32 32]\n",
            " [ 2 19  4 36 43 43 36 55 32]\n",
            " [ 2 48 36 51 25 16 49 49 55]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCXFrK535mqf",
        "colab_type": "text"
      },
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "bDb31s9w5mqg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ad619257-ddee-47d1-9339-4f2dbcb97746"
      },
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/keras_utils.py:68: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:79: The name tf.reset_default_graph is deprecated. Please use tf.compat.v1.reset_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:82: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:84: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:75: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/keras_utils.py:77: The name tf.InteractiveSession is deprecated. Please use tf.compat.v1.InteractiveSession instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "yJ3Km47n5mqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(64, activation='tanh')\n",
        "### YOUR CODE HERE\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "\n",
        "get_probas = Dense(n_tokens, activation='softmax')\n",
        "### YOUR CODE HERE "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9q2Q0e_5mqp",
        "colab_type": "text"
      },
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "jm2ioRRB5mqq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = tf.concat([h_t, x_t_emb], axis=1)\n",
        "    ### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next = get_h_next(x_and_h)\n",
        "    ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)\n",
        "    ### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4yRoFqF5mqt",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "eP2OcLnM5mqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c6410510-91a1-4409-b703-e570d3680d62"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3535: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0CMiOED5mqx",
        "colab_type": "text"
      },
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "r-WKqiIp5mqy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0MjTCMb5mq2",
        "colab_type": "text"
      },
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "_WhC53cH5mq2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "loss = - tf.reduce_mean(tf.log(predictions_matrix) * answers_matrix)\n",
        "\n",
        "### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-stKSGC5mq5",
        "colab_type": "text"
      },
      "source": [
        "# RNN: training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "QkidHEcG5mq5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "441eb248-473e-43f1-dfc6-b215c9923cd0"
      },
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU1fnA8e+bmclGIGxhDRgQFAEVNIAgooICapVaccG2Ql2ov1bbatVCrRvaFrF1ad3XuouiVgpUXFCWgkDYdwybhDVsCSHrZM7vj7kzmclMkkkykHDn/TxPHubee2bm3Nzw3nPPKsYYlFJK2VdcQ2dAKaXU8aWBXimlbE4DvVJK2ZwGeqWUsjkN9EopZXPOhs5AZa1btzYZGRkNnQ2llDqpLFu27IAxJi3csUYX6DMyMsjKymrobCil1ElFRHZUdUyrbpRSyuY00CullM1poFdKKZtrdHX0SikVDWVlZeTk5FBcXNzQWYmqxMRE0tPTcblcEb9HA71SypZycnJo2rQpGRkZiEhDZycqjDEcPHiQnJwcunTpEvH7tOpGKWVLxcXFtGrVyjZBHkBEaNWqVa2fUjTQK6Vsy05B3qcu52SbQL/rSBFTPt/IriNFDZ0VpZRqVGwT6I+VuHn+2y0szD7Q0FlRSikAUlJSGjoLgI0Cfbe0FFoku1iy7VBDZ0UppRoV2wT6uDihf5eWLNZAr5RqZIwx3HvvvfTu3ZszzzyTqVOnArBnzx6GDBlCnz596N27N/Pnz6e8vJxx48b50z711FP1/n5bda/s36UVs9ftY29eMe1SExs6O0qpRuKR/6xj/e78qH5mzw7NeOjKXhGl/eSTT1i5ciWrVq3iwIED9OvXjyFDhvDee+8xYsQI7r//fsrLyyksLGTlypXs2rWLtWvXAnDkyJF659U2JXqAPp1SAVi/J6+Bc6KUUhUWLFjAmDFjcDgctG3blgsvvJClS5fSr18/3njjDR5++GHWrFlD06ZN6dq1K1u3buXOO+/k888/p1mzZvX+/ohK9CIyEngGcACvGmMmVzqeALwFnAscBK43xmwXkZ8C9wYkPQs4xxizst45D+PUNG/DR/b+Aob2aHs8vkIpdRKKtOR9og0ZMoR58+Yxc+ZMxo0bx913381NN93EqlWrmD17Ni+++CIffvghr7/+er2+p8YSvYg4gOeAy4CewBgR6Vkp2S3AYWNMN+Ap4HEAY8y7xpg+xpg+wM+BbccryAM0T44nNclFzmHtYqmUajwuuOACpk6dSnl5Obm5ucybN4/+/fuzY8cO2rZty2233catt97K8uXLOXDgAB6Ph2uuuYbHHnuM5cuX1/v7IynR9weyjTFbAUTkA2AUsD4gzSjgYev1NOBZERFjjAlIMwb4oN45rkH71ER2H7HX3BZKqZPb1VdfzaJFizj77LMREaZMmUK7du148803eeKJJ3C5XKSkpPDWW2+xa9cufvGLX+DxeAD461//Wu/vjyTQdwR2BmznAAOqSmOMcYtIHtAKCOzUfj3eG0IIERkPjAfo3LlzRBmvSvvURPbma4leKdXwCgoKAO9o1ieeeIInnngi6PjYsWMZO3ZsyPuiUYoPdEIaY0VkAFBojFkb7rgx5mVjTKYxJjMtLexKWBFr0SSew8fK6vUZSillJ5EE+l1Ap4DtdGtf2DQi4gRS8TbK+twAvF/3bEYuNclFfpEGeqWU8okk0C8FuotIFxGJxxu0p1dKMx3wPX+MBub46udFJA64jhNQPw/eQH+0xI273HMivk4p1YgFNxPaQ13OqcZAb4xxA3cAs4ENwIfGmHUiMklErrKSvQa0EpFs4G5gQsBHDAF2+hpzj7fUJO9k/PnF7hPxdUqpRioxMZGDBw/aKtj75qNPTKzdgNCI+tEbY2YBsyrtezDgdTFwbRXv/RY4r1a5qgdfoM8rKqNlk/gT9bVKqUYmPT2dnJwccnNzGzorUeVbYao2bDUFAkDz5IpAr5SKXS6Xq1arMNmZraZAgIoS/ZHC0gbOiVJKNQ62DfRaoldKKS/bBfpmvsZYDfRKKQXYMNCnJHibHY6VljdwTpRSqnGwXaBPdDoAKCzR7pVKKQU2DPRxcUKSy0GhluiVUgqwYaAHaJLgoLBMA71SSoFNA31SvIMiLdErpRRg00Cf7HJyTOvolVIKsGmgT4p3UKRVN0opBdg00DdJ0MZYpZTysWWgT3I5NdArpZTFloE+Od5BYanW0SulFNg60GuJXimlwKaBXrtXKqVUBVsG+ibxTgpL3bZaWUYpperKloE+Kd6Bx0CJW9eNVUopWwb6RJd3YrOSMg30Silly0Cf4PSeVolb6+mVUsrmgV5L9EopZctA76+60RK9UkrZM9D7SvTFWkevlFI2DfRaoldKKT97BnpfHb2W6JVSyp6BvqKOXgO9UkrZMtBX1NFr1Y1SSkUU6EVkpIhsEpFsEZkQ5niCiEy1ji8WkYyAY2eJyCIRWScia0QkMXrZD0+7VyqlVIUaA72IOIDngMuAnsAYEelZKdktwGFjTDfgKeBx671O4B3gdmNML+AioCxqua+CNsYqpVSFSEr0/YFsY8xWY0wp8AEwqlKaUcCb1utpwDAREWA4sNoYswrAGHPQGHPco2+iluiVUsovkkDfEdgZsJ1j7QubxhjjBvKAVsBpgBGR2SKyXETuC/cFIjJeRLJEJCs3N7e25xDCV6LXOnqllDr+jbFOYDDwU+vfq0VkWOVExpiXjTGZxpjMtLS0en+pdq9USqkKkQT6XUCngO10a1/YNFa9fCpwEG/pf54x5oAxphCYBZxT30zXxOWIwxEnWnWjlFJEFuiXAt1FpIuIxAM3ANMrpZkOjLVejwbmGO+qH7OBM0Uk2boBXAisj07Wq5fgjNOqG6WUwlu1Ui1jjFtE7sAbtB3A68aYdSIyCcgyxkwHXgPeFpFs4BDemwHGmMMi8iTem4UBZhljZh6ncwmS4IzTEr1SShFBoAcwxszCW+0SuO/BgNfFwLVVvPcdvF0sT6gEp0O7VyqlFDYdGQuQ6NISvVJKgY0DfYLToXX0SimFnQO9luiVUgqwc6B3xmk/eqWUwsaBPtGljbFKKQU2DvTefvRaoldKKRsHei3RK6UU2DrQa2OsUkqBnQO9y6FVN0ophZ0DvTNOq26UUgo7B3rtR6+UUoCdA73TQanbg3cSTaWUil22DfSJLl1OUCmlwMaBPsFpLRCuDbJKqRhn40DvK9Frg6xSKrbZNtAnWguEa9WNUirW2TbQ+0r0OlWxUirW2T7Qa4leKRXr7Bvo/VU3WqJXSsU22wb6RF+JXnvdKKVinG0Dva9EX6wleqVUjLNvoNcSvVJKAbEQ6LUxVikV42wb6H396LV7pVIq1tk20GuJXimlvOwb6LV7pVJKAXYO9NoYq5RSQISBXkRGisgmEckWkQlhjieIyFTr+GIRybD2Z4hIkYistH5ejG72q+ZyxOGIE+1eqZSKec6aEoiIA3gOuBTIAZaKyHRjzPqAZLcAh40x3UTkBuBx4Hrr2BZjTJ8o5zsiCc44LdErpWJeJCX6/kC2MWarMaYU+AAYVSnNKOBN6/U0YJiISPSyWTfedWM10CulYlskgb4jsDNgO8faFzaNMcYN5AGtrGNdRGSFiMwVkQvCfYGIjBeRLBHJys3NrdUJVCfR5dDGWKVUzDvejbF7gM7GmL7A3cB7ItKsciJjzMvGmExjTGZaWlrUvjzBGUexVt0opWJcJIF+F9ApYDvd2hc2jYg4gVTgoDGmxBhzEMAYswzYApxW30xHKsGpJXqllIok0C8FuotIFxGJB24ApldKMx0Ya70eDcwxxhgRSbMacxGRrkB3YGt0sl6zBJfW0SulVI29bowxbhG5A5gNOIDXjTHrRGQSkGWMmQ68BrwtItnAIbw3A4AhwCQRKQM8wO3GmEPH40TCSXQ6tNeNUirm1RjoAYwxs4BZlfY9GPC6GLg2zPs+Bj6uZx7rLMEVR0GJu6G+XimlGgXbjowF7UevlFJg+0CvjbFKKWXrQJ8c7+BYiQZ6pVRss3Wgb9EknsOFpQ2dDaWUalC2DvTNk12UuD0UlWqpXikVu2wd6FskxwNoqV4pFdNsHeibJboAyC8ua+CcKKVUw7F1oHc5vBNoustNA+dEKaUajs0Dvff0ysq1L71SKnbZOtA7fSV6j5bolVKxy96BPk5L9EopZetAH+/0lujLtI5eKRXDbB3ofSV6t5bolVIxzN6B3qEleqWUsnWg1143SikVI4He7dFAr5SKXbYO9M44rbpRSilbB3p/iV4DvVIqhtk80PtK9Fp1o5SKXbYO9E5tjFVKKXsHepdOgaCUUvYO9AlOBwCFuvCIUiqG2TrQO+KEpglOjup89EqpGGbrQA/QLMlFfpG7obOhlFINxvaBvmmiU1eYUkrFNNsH+tQkF3lFGuiVUrHL9oG+dUoCB46WNHQ2lFKqwUQU6EVkpIhsEpFsEZkQ5niCiEy1ji8WkYxKxzuLSIGI3BOdbEeufWoiu/OKMEa7WCqlYlONgV5EHMBzwGVAT2CMiPSslOwW4LAxphvwFPB4peNPAv+tf3Zrr33zJIrLPFp9o5SKWZGU6PsD2caYrcaYUuADYFSlNKOAN63X04BhIiIAIvJjYBuwLjpZrp3WKfEAHCgobYivV0qpBhdJoO8I7AzYzrH2hU1jjHEDeUArEUkB/gA8Ut0XiMh4EckSkazc3NxI8x6Rlk28gf7QMQ30SqnYdLwbYx8GnjLGFFSXyBjzsjEm0xiTmZaWFtUMVAR6bZBVSsUmZwRpdgGdArbTrX3h0uSIiBNIBQ4CA4DRIjIFaA54RKTYGPNsvXMeoYpAr3X0SqnYFEmgXwp0F5EueAP6DcCNldJMB8YCi4DRwBzj7eZygS+BiDwMFJzIIA/QLNEFoNMgKKViVo2B3hjjFpE7gNmAA3jdGLNORCYBWcaY6cBrwNsikg0cwnszaBSS4x044kRHxyqlYlYkJXqMMbOAWZX2PRjwuhi4tobPeLgO+as3EaFpopOjxTrfjVIqNtl+ZCx4q2/ytR+9UipGxUSg1xK9UiqWxUSgb5bo0jp6pVTMiolAryV6pVQsi4lA7118REv0SqnYFBOB3rv4iJbolVKxKSYCfbNEFwUlbso9OlWxUir2xESgb5roHS5QoKV6pVQMiolA3yzJOw2C9rxRSsWi2Aj0VoleA71SKhbFSKD3TWymVTdKqdgTE4G+ebJ3quKDusqUUioGxUSgz2idDMCW3GrXP1FKKVuKiUCfHO8krWkCC7IPsCYnr6Gzo5RSJ1RMBHqAJJeDJdsOceWzC/Bof3qlVAyJmUCf4Kw41b9/uakBc6KUUidW7AR6V8Wp/nvF7gbMiVJKnVixE+idDv9rnQpBKRVLYijQV5yqO4JA/+r8rdpLRyllCzEZ6Ms9Ho5WM0q21O3hsZkbGP3CQgAyJszkqS83H/c8KqXU8RBDgb6i6uZwYRlnPvwF32zaHzatx3hL/IEjaZ/5+vvjm0GllDpOYibQHysNnf7g243hA31ZuQcAA7it10opdbKKmUA///sDIfsWbzsUNq2vsdYYQ6kGeqXUSS5mAv2U0WeF7Nu49yjLdhxmxurdrPjhsH+/r7HWY7z19T6fr917/DOqlFJRFjOB/rrMTgw6tVXI/nunreKO91Zw9fML/fsCu18Gluhvf2cZuUdLjm9GlVIqymIm0Fdla+6xoO1Styeoh01giR7Qqhyl1EknpgK9iWCc1NSsnXywdKd/u3KgN5F8iFJKNSIRBXoRGSkim0QkW0QmhDmeICJTreOLRSTD2t9fRFZaP6tE5OroZj+63OUeVu08ErSvcgle47xS6mRTY6AXEQfwHHAZ0BMYIyI9KyW7BThsjOkGPAU8bu1fC2QaY/oAI4GXRMQZrcxHW4nbw7RlOUH7Nu8LHh0byahapZRqTCIp0fcHso0xW40xpcAHwKhKaUYBb1qvpwHDRESMMYXGGF8H9kS8XdMbjKnh60vcofXvZZX2ab96pdTJJpJA3xHYGbCdY+0Lm8YK7HlAKwARGSAi64A1wO0Bgd9PRMaLSJaIZOXm5tb+LKLkcGHoUoNuT3BgLyvXEr1S6uRy3BtjjTGLjTG9gH7ARBFJDJPmZWNMpjEmMy0t7bjl5Q8je1R7/N8rdoXsKygpD9quHPiVUqqxiyTQ7wI6BWynW/vCprHq4FOBg4EJjDEbgAKgd10zW199O7egdUp8lcf/OSc7ZF9eUfDkZ1qiV0qdbCIJ9EuB7iLSRUTigRuA6ZXSTAfGWq9HA3OMMcZ6jxNARE4BegDbo5LzOro2s1PNiQLsPFQYtL1lfwF5RWUM+uvXjHx6XkSf8eX6fdz6ZlatvlcppaKlxh4wxhi3iNwBzAYcwOvGmHUiMgnIMsZMB14D3haRbOAQ3psBwGBggoiUAR7gV8aY0ElnTqB7h5/OC99uCdqXkuCkdUo82w8WhqT/tFJ1zn0fr+aV+VvZnVfM7rziiL7ztre8Qd4Yg4jUMedKKVU3EXV1NMbMAmZV2vdgwOti4Now73sbeLueeYyquLjQQDvjzsGUuD2MiLCE/v3+ii6Xs9bsYWSvdmE/tzK3x+ByCEcKS4l3xpEc32h7miqlbCSmRsaG43IIGa2bkBzvqDlxGL96dzlX/HMB2w4cqzGt26rf7zPpy4hvKkopVV8xGehH9mrnf+2rSunYPInxQ7rW6fM27Mnn4r99y42vfFdtusBRtjsPFdXpu+rqyS83820VC60opewtJgP9szf2JetPlwDgq3CJixP+ePkZNE92ATC4W+taf+7CLQcpcXu7Y67dlUfGhJls2JPvP15Ww2Cr3UeKyJgwk7mboz+W4B9ff8+4N5ZG/XOVUo1fTFYSOx1xpCZ5A/pPB5wSdGzGnYPZuOcoLVPiWZBd+3bjI4VltG3mYPY679z1H2ZVjDUrKHbTqklF984VPxymb+cWfLV+H51aJvurcx76bC25R0uYe9/FtE5JqHUelFIqUEwGegCXI46Nj44k3hH8UJPeIpn0Fsmsycmr0+duO3CML9fv8z8pvPG/7f5jF/3tW0afm+7fvvr5hSy5fxi3vpVFYGccX++fRVsOcuXZHeqUD6WU8onJqhufRJejyt4yjoD97VODB/PefelpVX7mHe8t50//XsvUrJ1hj1eeNO0HK6iHmxWzck9Mj8fw2oJt/GHaaorLykPfoJRSYcR0oK+O0+GNsqe0SmbRxGFBxzo2T6ryfQcKvPPl7MuPbCWqcGvZ+gjBkf7j5Tk8OmM9U7N28sX6fRF9Pugc+krFOg30VfAV6H0l+3/9op//WEqit8brrPTUen/PM19/X+WxyiX6I4UV0zFE0G3fr1ynVlYqpmmgr4Kvg4zTiqgXnd7GfywlwRvoT1RBefxbWfR44L9Bgd8ZF/ml0zn0lYptGuir4JulMi7MlAVJ1uCqmua3r68X527h8mfm88X6fRSXefhHQOn/9neWcehY6LTKgd5etJ0Ne/IjDvQej+GVeVs5WlxWc2Kl1ElDA30VWjXxdmu8uEebkGO+Ur4x8PnvLmDcoIyg493apEQlD6tz8lgf0A8/vzh4Kv+Za/ZU+/4HPlvHZc/MpzzCGTfnfp/Ln2dtYNJ/1tc+s0qpRksDfRXapSayaOJQ7hl+un/f9DvO594Rp/tL+cZAj3bNuPB07xz6Q05LY/vkK/j3r88P+5lDw9w06qO4NLjnze4jRazJyWNLbkHQlAxnT/rC/7q6+nrfFA0HCiJrSC73GGav26uNvUo1chroq9E+NSmom+VZ6c359cXd/Nu+8Fa5ciclwUlTq8G2b+fmgLeU/88xfcN+T3qLqnvxVOfPszaw+0gR+/KLcZd7uPCJb7jy2QUM+/tcLv7bt2Hf4xud6y73MPGTNbz93Q7/sXhnnJXGYIypcdnEF+du4ZdvL+PrDTq1glKNWcwOmKoPX9fLBCswir+EX1GyXXDfUHbnFXFG+2as2nmEXh2a4QwYnNWmaQL7j3pLzh1Sk3jlpkwue2Z+rfPy5JebmbYshxG92ka0KEppuYdEl4Ppq3bz/pIfAPj5eadQ4i5n7OtL/Gl++8FKvt20n1UPDQ+aWtnjMVz57AJ+M6w7y3cc9qevyftLfiBr+2H+ft3ZtT5HpVT9aIm+Dk5v25Q7h3bj2Ru9JfRwPR1Tk12c0b4ZAGd3ah4U5AG+ueeioG1f2ppMGX1W0PZhq0F29rrI+tWf9fAXXPviwpB+/ruPVMytv2F3PtNX7Sa/2M3Hy4Pn4y8odbNudz6//3AVR0u8bQaRNPZO/GQNHy/PqTHdyebDpTvJmDCTgxFWdynVEDTQ14GI8Pvhp5PeItna9u6PpKp6YNdWXNa7HU0SnEwa1QuoqLq5c2i36t4KQPdKDb1fb6x9tcnS7Yd5/PON/u2bXl/COwFVOL4ADnDPR6u4473llJV7yN5/lJ+9uth/zPdEs/tIEQu3hA78Kiv3cN1Li1i0pWJVSY/Nunq+v9T7VLTjUOiiNSeSMSZoAj2lAmnVTRT4RrBG0t3y/fHn+V/fNDCD1ikJXHiatzH398NP969b2zTRyVGrl02X1k38jatNEpxsn3wFGRNmRi3/8zbnMq+aGTNnrN6DAWauDu7l45snaPJ/vTeNJX8cRptmiYx8eh7pLZJ48Ee9WLLtEPd9vMr/nj35xTRPctEkwV5/eg3dHv3vlbu4a+oqXrkpk0t7tm3YzKhGR0v0UdAlrQkAl5/ZvtbvvfzM9mGD3tL7L6FXB291zjmdW/j3J7m8ffg/un1gxN/haxCuj8pBvqDEzeJth4L2+W5GG/ce5asN+/1TNrsCBnedP3kOlz45N+h9m/Yejajnzr0freKtRdvrkPvjp7EsDLlhz1EAtuYW1JBSxSIN9FHQsXkSGx8dyY39O0ftMxNdDsYOzACCp0JIcHkvWb+MlmHf9/g1Z4bsczmqvsy+efnroqAkuF//w/9ZT9b2iuCfbw28qjxx3O68YjImzGT97nzmbs5lxNPz/JO9fbh0J4u3HiScj5bl8OBn6+qcX59odgetaKhu2CK9r0pMlyRW4Wigj5JElyPqC3/7qoKEisZaX4ke4Onr+4S8p3PLJiH7xl8QfuWse4afRovk+LDH6mLDnnxGv7jIv/2V1e0ye3/4UubyHw6z3XoKWLPLOy30fR+v5vqXq1+pq64KS914PIYuE2dxz0eran5DBE5UXN2XX8x/qxkgV9HVVyO9CqWBvhHzFTxF4J1b+vPcjefQNNHlP/7jvh39r6dccxZvjOtHoqvikl5+Zju2/uVyLunZlu2Tr+DdWwcEff6vLuoWNE4g2l74dku1x5snu/zfX+r2MCsgkP3rf9vImDCTAwUlXP38/2rdJnGksJQJH6/2P3XkF5fR88HZ/P3LTUDFdNFTPt/o/+xHZ6zn2TlVTzJXneNdR3/dS4v4v3eXVzm2wWMaZ4n+2TnfkzFhpu0a4U829moRs4mBXVuF7GuVksAVZ1XdBnBdv06At9Tqc+VZHYKqTc7v1poVD1xK30e/BEKrVMJJTXKRV3R85r65470V/tdzNu7ng6UVc/j/w2qUnvDxalb8cCTkvcYYRIS9ecW8uWg79w4/HREocXu47a0smiY6mbVmL4eOldKySTzDzvA2UL7z3Q/+z9i09yjPWzej4U/NZfM+75PHHUO7R3wO/h5XwHdbD9KldRPaNkus9j11scNat6C03BPSVRcCCwWNK9L7ZmctcXv8c0TV5NX5WxlyWhqntW16PLNGqdvDE7M38uuLu9E8ik+2jZEG+kZm++Qr/HXIzazlDts0rTpw/Py8U9i4t6JbXXK8t1dOWbknbN18C2spw8A59Qd3a82C7AMkuuIoLvMwZfRZ3DdtNR1SE1k4cRhPfrGJLQeOhTTIRqJJvINj1lQNTROc9O/SMmyXUN/gMR/fhG1fhRl1u/NQIRdM+YY7h3Zjxuo9bDtwjK6tm3CvlefdeRVjAnzz9vtGKvu6hAI8NrNiTh9fkA/HGENeUVlQMFi7Ky9oqclyj+GGl7+jTdMEltwf2u6xOucIHZsn0SrM0pClbg8LsnPZeaiIq87u4L9G4ZS6PVQXk6IV5ncdKaJt04Sgm8qUzzdyVnpzRvZuV+X7PB4TVIDwThdiKC4rjyjQl3sMj83cQJMvN7Nu0sh6nUNNPl+3l1fmbyOvqIwpo+09kE8DfSPkK5Vd1rsdU0afxag+VS8n+OiPe4fdX10D7LI/XUJiQF3/q2MzKSnz8M2m/fz1vxv8TxRl1uP23cNPZ87GfREH+ubJLv/c+QmuikBfUOr2f2Z9zLDy4euKCnDvtNUAQUE+0CvztwHBC7RXt+iLzzcb9zN91W4+XbGL5Q9cSksrCP/onwsA6Jfh7RFV6vZ+ru+GtWTbITbtzefnAzPweAxXPfs/urVJ4au7Lwz5jgc/W+t/mpn//QFG9enAn/69lryiMob2aMPr4yrWQtiXX0JhaTkdKi1+4ysc1LUm7kBBCc2TXDgdcezPL+b8yXP45YVdmXjZGezLL6bcY/xPP9snXxH2M6Yty+Gej1ax5P5h/sKJb16oEnf4KqctuQV8v+8oI3t7n1Z9K6cdKz3+K6j5fmeFlb5r5uo9/Pq95ax6aLh/bemTndbRN2IiwnWZnUhwRvbIG6lWKQlBXToTXQ5Sk138uG9HFv/xEpKtkldgUHRHOAMmQEarigbhwCcHY6DUXf//wPO/r7rPf00OF9ZcDXWgoMTfNfQX/1rKpyu8o4N3HDzG2l15/DngSWDpdu80EIE9kD5dkcN1Ly3igc/WYYxhT7735lNVo/TSgJ5KhwtLufP9Ff7qsjmVnn5GPD2PQZPnsLPSAC1PPapuisvKyXzsKx6wejT51ix+ae5WAAb85WsGTZ4T9r3lHsOf/r2G7QeOMcUahLc/YNS178bjC+D5xWVs2nvUf3zY3+dy+zvL/du+G0JtTmN/fjFzNka+4pqPrzBU+W/7xbnWDS1gYsC6cJd72JNX5N8+WFBCtz/OYsm2QxSWulkQQUEjWjTQqxCpSS7aNE1g0qiKpwXf1MtTRp8VdinFl39+rr90+9MBFd1Mf31xt6B+/EVlNaLVN34AABPqSURBVM+LU5OFW8J3v4yWzMe+4urnFvLh0uB1f1/4dgs/+ucC/9NBoMDZQu+aWtGj55Plu2oMGM0CSo2RlsgvmPINn67wNijf+uZS/+R0cQK3/Gspf5m1AYBxbyzhrqkrq/ycwlI393+6FvDOR1RcVh40e+mTX26uNh9rduXxznc/8Ov3lvufZgLXM/ZV4xRbN86fvbqYEU/PC/kcX2Ot773h1oGoyvUvf8fN/8qq9UpqvunGfWtPhLNp71FGv7AwqO0rUlNmb2LgX+f4f58rfjiC22N4ce4W7v1oNT97bTG7jhTV8CnRoYFehXA64lhy/yVcdXZFlVHXtBTWPjKC6zI7+XvKPPCjnsz8zWDeu20Aw3u189dhB9bFXnJGGz79lXfaZhFvbxjwNjiHq5KqqsH5OHYOCmv9nnzu+3h10L5vN1X9JPHE7E1h9//+o1V8E1AqD9eHvyTg5heuRF5VTxvfDSWwHcPgnRbj5Xlb/Xn+dMUuMibM5MyHZoeMfXhz4Y6gOYj25RcHLWjzjzBLXW4/cIyHp69jYfYBf2+fdbsr2ol833GksNQ/utt3jqtzvN1oDxSUBPWkyrYGevlK9L7r7fEYlu04TMaEmXyzcT+b9h5l2Y7wA/VqCsZv/G9bUAnbNzlhVZMBHi4s5dEZ68nacZgpn4de36LScj5dkVPluAzfdT9orSNd8X0ef3fi0iqqtKItokAvIiNFZJOIZIvIhDDHE0RkqnV8sYhkWPsvFZFlIrLG+ndodLOvTiTfEooVyyum0atDKoNObQ1UNAQ6A6KyrzHvhZ+ew5d3DfEHkWdv7MszN/SleXJwHWi7KnqsJMc3fHNSJLN0hvPqgoongMOFZaz44TDGGJbtOMTET9YELS6zLz+0jaG6UvXC7ODH/6eqSXu0xM273+0gY8JM/vjpGl6ZtzVoziOAV+Zv9Qemqtz4ynf8a+F2bnx1MQeOhk7mdqzEWyoPLK0GlvIBPsoKnuBu+FPz+Gr9Pn+6snLDltwC3li4nWteWAjA019tZsTT87jmhUWE47vZfL/vKPvyi3l70XYyJswkr7CMXUeKeOQ/6xn/1jJ/et/lrKpEP+6Npf4G938t3B5y/InZm7hr6qqgRnmf7P1H/XX/virQwK7Evn0nai2HGv/3iIgDeA64FMgBlorIdGNM4DJEtwCHjTHdROQG4HHgeuAAcKUxZreI9AZmAx1RJ7V+GS3ZeuAYTSoF3+oety+zpof4x5i+vPjtFv9ArS/vupB+f/7Kny5coL8+sxPDzmjDX2ZtoG/nFv468xPl2nPTmf/9AfaGCcK19emKXTw6Yz3ndW3Jd1sPhRz3daMM9Hw14xFuDJhkDoLbIL5Ytzck/SJr1PF7i38IOQbB3U+rEtjgPf7tZSHHj5W46Tvpi6CpO57/dgvnnFKxXfkGA3DrW1l8+qtB/u1hf5/LdZnp/u3KjaaV3fDyd6x5eDiXPhVcNZSdW0ALq0CRX1zGsRI3h46VcttbWUBoiT7SJUIPHvPe5NbsyuP8U1v7q6k8HsMlT1bkoci6eflK7yVuD3us32FVjdTRFkmJvj+QbYzZaowpBT4ARlVKMwp403o9DRgmImKMWWGM2W3tXwckiUho/zJ1Upn0417M/M1g2qUGB+XAWTx9E7VVdvHpbZj6y4H+/xRpTROY/bsh/uNlAaWrm8/vAngfeYf3ase3915cZS+jmmx8dCT9q5g2oiant2ta76qjMdb0GJusrrDhgny0hQvCOYePf53wocJSDheWBXWjnbs5l7cW7ajmXV7vVroBBbbpBAb65T8cprisnBteDi7df7wsdCrsa15Y6K9O2nGwkF4PzeaCKd/4j0fa6Dpkyjc89Nla/zQfvq66Uz7fxIyAwX6V690LStxk7y/g6a+81WD5AeNSStyeE1KqjyTQdwQCW6VyCC2V+9MYY9xAHlB51M81wHJjTMiznoiMF5EsEcnKza17jwp1YiQ4HfTqkBqy3xfoPQZeG5vJhgj7QZ/eriljB57C8J5tGX1uRQluRC/vIKcBAQPIUqqY9TLTKi3+5JyKP83AlbsSXQ7/PEHhtGladfnDGEJK82NqOa/R1dYo5kjXDahOVb+DSFTV8yeafLOZVrbjYM0BdVqlQP2fVbv9rwMD6E+eX8gtby4NuWFW1Tnsqmf/V+V37j9aElLvH84Phwp5c9EORr/onXr7SMDT02/eX8FFT3zD7z9cFdQwD94nnNvfWeavl98acPx3H6ygy8RZfLZyF7/9YEW1VW/1cUIaY0WkF97qnF+GO26MedkYk2mMyUxLC18SVI2ff6UtDE5HXMQjIQEeGdWbl2/KpE3TRNpbTwoDurZi4YShQY3CAB/+ciAfjD+P/l28JfQOqYn+nj3d21SMpgycLgIgLcxgJZ8l91/CtDAzgo4+N52fDzwlZDTqlWdXP1Npi2QX12d6RysnOOP8VQeRjjL+1UWnVnnsfxNOzqauwAbbaPhfdmjvq6PFdRvFvXlfAfd8tMrfRbQmY175zj8Yz2f7wUI+Xp7DTdZKbYH5rOoG6+vK+tsPVvLZyt3sPHx81jWIJNDvAjoFbKdb+8KmEREnkAoctLbTgU+Bm4wx1U9+ok5q/nkc6/kk+uXdF7LMmlWz8sAggP5dWnJe11a8c8sAnhh9Fh/93yDap3rTNUmouLn87hLvVAbLH7g06LPGDcpgxp2DaWaNlm3bzHsDyMxoyee/u4AHftTTH5h/O6w7iS5HUJfSXw7pyqBTW1cbcFc8ONy/vnCL5PiQm05Nbq8m0KcmuXjUWrSmLhKrebIJFK767Yu7hvDCT8+p9WcBrI9yoA/HVz1SWxM/WcO0ZTk8/+0W1u6Kbj59S3ZGInDkdjRF8qlLge4i0kVE4oEbgOmV0kwHxlqvRwNzjDFGRJoDM4EJxpiqn52ULcT5S/T1k5LgDDtVQGXxzjiuzexEx+ZJ3DTwFCb/5Exu7N+Z18dl8uCPejKiVzu2T77CP5rVF+iPlbjp3TGVj/9vEL84P4MFf6gI2D3aNeOWwV38g2l8/751c38m/+RMtk++gomXnwEEDwb70xVn0Mr6nies5R7TrOqgiZf3ICUxuLqldTXnN+32gTRLdLH64eH0aOd9QqncNlFdn/EnrzubbX+9nNsvPJV3bhngXyDGJ9xcPNPvOD9o++vfX8ibN/fnpoGn8PLPz/Xv79q6SVBV2qBTWzM1YDGdcC7t2ZYhp6X5GyUry2iVXO37q5OS4GTq+POCrnM0XXNOeo1p7hl+WkSfdd/I06s9nprk4q5LI/us2qox0Ft17nfg7TGzAfjQGLNORCaJyFVWsteAViKSDdwN+Lpg3gF0Ax4UkZXWT5uon4VqFO4dcTqDu7VmaI8Tf4mdjjhu6N8ZpyOOoT3acvPgLiFp2jf3BjjfwJ7ubZvy0JW9wk4X8fq4flyXme6vu+/UMpkbqqmXv/WCrsz4zWBGn5vOlVZVU1K8g+2Tr2BUn46kJDi5/EzvHDFd05rw3cShdG0dOqU0eFcUA2iW6OIPI3sAcP6pwU1egev0+qp5zuyYyqe/GsRPzklHRJhwWQ8Gd2/N5j9fxsZHR7LqweHccXE33rkleBZTgIxKefEN/Z80qjfDe1XMbeN0xNGySTzbJ1/B/Psu5h9j+jKgayteH5fJe7eFfi7AU9f38a+vHKip1dZwQffIq2t/0je4efDC09L8N57AxXierGYRet/NMxJ/uKz64AzQp1OLsPsHdAlu/L/mnPRqq+T+cvWZ1c5rVR8RPScYY2YZY04zxpxqjPmzte9BY8x063WxMeZaY0w3Y0x/Y8xWa/9jxpgmxpg+AT+1X+RUnRQ6tUzmnVsH1Kux8HgadGorru7bkQd+dEaNaXt3TGXK6LNrnOFz6vjzeG1sJgDtU5P427VnB80jFMjXi6h9aiJOR5y/z/ibN/cPWgAmsG3j4h5t2D75CrqmBa8V7AmoH7vr0tNYP2kE/7lzMH07hw86vmku7hlxOp1aJtO7Y/Bi9M0qVS1V3g6nU8tk/7Ue2qOtfzyFz6bHRrLtr5eTkuAM+byOzZMY1M0boP94eej1aJYY/m9oyuizWDRxKL8Z5q2WC3yy6RIw9UbnlskhTyk+H//fIP9NBrwD/wBcjuBr7XJIRPP7p4VpyHfGCVN/Gdzmk+hyVLuEZvxxqrYBHRmrYkiC08FT1/ehW5voTX87oGsr/xTINenTqTnjBmUw+Sfeqp2WKd6qht4dmtE6JcG/dGRVcxv17tiMO6x6f18peNrtA3E54mo9oOzZMedw7bnB1RKrHhruf13foPPf315AgjP8Yjw/O68zn/5qEE9f35ev7r6QpHgHGx8dydmdKqbKCNfOc8fF3XA64mifmsQpLb3VPT07VNyw4uLEPwCvaaKLqmq3miQ4g6rSfH31b620QE+zRBetU+L91+XcU1qw+uHhDAt4Yj2zYyqnBFQ9/aRvR569sS+LJg4L+d4kl4NfnJ8Rst9X5RTYvhRtjbPopZQNOR1xPHxVRSPqKzdlMn/zAX97xDu3DGDzvqNVLgYz484L/K/PaN+sylkkI5HRuglPXHs2HwV0Z0xNcnHbBV34z6raT0ddmW9FtHAeuaq3/xx9cygluhx89uvz6TPpC649N533l+wMed/1/Sr6hFzVpwNFZeVcl9kpJB14p6X2TTnQo11Txg/pyjmdW/i7AHdrk8KevGK+uecimia6WPvICJJdjqDFctKaJiAivHlzfzIf+4pbB3ehWaKL18b180/f8J87BwMwrEcbzkpvzm8vqXotA5dDiHd6q/BmrakYzPbsmL6sysnjvC6h61BEiwZ6pRpI+9Qk/4Ix4F0rYECYRWeOp5d+fq6/OyvA/Vf05P4retb5805NC9/uAN6Sa2Gpu9pVzVY+6H2qWJ2TF7L4fCCXI46fnXdKyP6+nZrzzaZcmiQ46dA8ibdu7k+/jJYhXX3/cUNfZq/b628P8VVBvXvrADq1SObdxTv8n986JSHkpjrrNxewdneef/u1gKmkA00a1cu/zrHv6eZPV/RERPzTfndNS2FQt9Zh3x8tcqLmWohUZmamycrKauhsKKUCvLt4B82T4qtd5awmxWXlGENE4yvyirzTGV/3UsXI1+8mDgsZjV3ZUWsa5Mw6joKOtq25BQz9+1wgdB7/oX//lq25x9j02MioTEUuIsuMMZlhj2mgV0o1VnM35/L9vqOcmpbCxQ3Qmysa8orKyC8qo1PL4G6k+/OLWZ2TxyU9I2vjqYkGeqWUsrnqAr32ulFKKZvTQK+UUjangV4ppWxOA71SStmcBnqllLI5DfRKKWVzGuiVUsrmNNArpZTNNboBUyKSC9S8inDVWgMHopSdk0GsnS/oOccKPefaOcUYE3Zy/0YX6OtLRLKqGh1mR7F2vqDnHCv0nKNHq26UUsrmNNArpZTN2THQv9zQGTjBYu18Qc85Vug5R4nt6uiVUkoFs2OJXimlVAAN9EopZXO2CfQiMlJENolItohMaOj8RIuIdBKRb0RkvYisE5HfWvtbisiXIvK99W8La7+IyD+s38NqETmnYc+gbkTEISIrRGSGtd1FRBZb5zVVROKt/QnWdrZ1PKMh810fItJcRKaJyEYR2SAiA2PgOt9l/V2vFZH3RSTRbtdaRF4Xkf0isjZgX62vq4iMtdJ/LyJja5MHWwR6EXEAzwGXAT2BMSJS9xWOGxc38HtjTE/gPODX1rlNAL42xnQHvra2wfs76G79jAdeOPFZjorfAhsCth8HnjLGdAMOA7dY+28BDlv7n7LSnayeAT43xvQAzsZ7/ra9ziLSEfgNkGmM6Q04gBuw37X+FzCy0r5aXVcRaQk8BAwA+gMP+W4OETHGnPQ/wEBgdsD2RGBiQ+frOJ3rZ8ClwCagvbWvPbDJev0SMCYgvT/dyfIDpFt//EOBGYDgHS3orHy9gdnAQOu100onDX0OdTjnVGBb5bzb/Dp3BHYCLa1rNwMYYcdrDWQAa+t6XYExwEsB+4PS1fRjixI9FX8wPjnWPluxHlX7AouBtsaYPdahvYBvhWE7/C6eBu4DPNZ2K+CIMcZtbQeek/98reN5VvqTTRcgF3jDqrJ6VUSaYOPrbIzZBfwN+AHYg/faLcP+1xpqf13rdb3tEuhtT0RSgI+B3xlj8gOPGe8t3hb9ZEXkR8B+Y8yyhs7LCeYEzgFeMMb0BY5R8TgP2Os6A1hVD6Pw3uQ6AE0IreKwvRNxXe0S6HcBnQK20619tiAiLrxB/l1jzCfW7n0i0t463h7Yb+0/2X8X5wNXich24AO81TfPAM1FxGmlCTwn//lax1OBgycyw1GSA+QYYxZb29PwBn67XmeAS4BtxphcY0wZ8Ane62/3aw21v671ut52CfRLge5Wa3083gad6Q2cp6gQEQFeAzYYY54MODQd8LW8j8Vbd+/bf5PVen8ekBfwiNjoGWMmGmPSjTEZeK/jHGPMT4FvgNFWssrn6/s9jLbSn3SlXmPMXmCniJxu7RoGrMem19nyA3CeiCRbf+e+c7b1tbbU9rrOBoaLSAvrSWi4tS8yDd1IEcXGjsuBzcAW4P6Gzk8Uz2sw3se61cBK6+dyvHWTXwPfA18BLa30grcH0hZgDd4eDQ1+HnU894uAGdbrrsASIBv4CEiw9ida29nW8a4Nne96nG8fIMu61v8GWtj9OgOPABuBtcDbQILdrjXwPt42iDK8T2631OW6Ajdb554N/KI2edApEJRSyubsUnWjlFKqChrolVLK5jTQK6WUzWmgV0opm9NAr5RSNqeBXimlbE4DvVJK2dz/AwN9s56pNYg4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIraDv9I5mq7",
        "colab_type": "text"
      },
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "8zBsXm-K5mq8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "e9RkUf9X5mq-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        #print('x_probs:{}'.format(x_probs))\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "OPrQpipG5mrB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ad25100c-1e1e-4d0d-da48-739e9aab60d8"
      },
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Trump'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Trumpe\n",
            " Trumpy\n",
            " Trumpen\n",
            " Trumpiee\n",
            " Trumpole\n",
            " Trumpee\n",
            " Trumpele\n",
            " Trumpetta\n",
            " Trumpun\n",
            " Trumpa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WCjuEQl5mrF",
        "colab_type": "text"
      },
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "-cnjD6NW5mrF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"vZ83TBIjSp3pRdYL\"\n",
        "COURSERA_EMAIL = \"rdlulu@gmail.com\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "C8rVwQJ65mrI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "193969f7-25ea-4c93-a605-e18f1845f771"
      },
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u34iT2mg5mrL",
        "colab_type": "text"
      },
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "Fkxa-2x75mrL",
        "colab_type": "text"
      },
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "BG1TXIHO5mrM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "e52ad1d8-05f8-49fa-ae77-c039bc86c11e"
      },
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "WARNING:tensorflow:Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f5ae806b908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "WARNING: Entity <bound method CustomRNN.call of <__main__.CustomRNN object at 0x7f5ae806b908>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Bad argument number for Name: 3, expecting 4\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7lyevOk5mrO",
        "colab_type": "text"
      },
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "yuopCzHC5mrO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "947f3dae-8255-4938-9f82-59133d1df4ca"
      },
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "_BdS8BlP5mrQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9be7fdcf-cb00-4c9e-e4ab-324fdd5fe803"
      },
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-35-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}